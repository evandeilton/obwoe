% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{woe_gains}
\alias{woe_gains}
\title{Gains Table Analysis for WoE Binning Results}
\usage{
woe_gains(
  binning_result,
  sort_by_woe = FALSE,
  include_all_metrics = TRUE,
  selected_features = NULL,
  verbose = FALSE
)
}
\arguments{
\item{binning_result}{list output from \code{chimerge_woe}}

\item{sort_by_woe}{Logical, whether to sort bins by WoE (default: FALSE)}

\item{include_all_metrics}{Logical, whether to include all metrics or just essential ones (default: TRUE)}

\item{selected_features}{Optional character vector of features to process (default: NULL)}

\item{verbose}{Logical indicating whether to print detailed processing information (default: FALSE)}
}
\value{
list with one element per feature, each containing:
\itemize{
  \item \code{gains_table}: data.frame with detailed metrics for each bin
  \item \code{summary_stats}: list with overall statistics
  \item \code{variable_type}: String, variable type
  \item \code{sorted_by}: String, sorting method used
}

The \code{gains_table} includes the following metrics:
\itemize{
  \item \strong{Basic Information}: bin_id, bin_label, counts, woe, iv
  \item \strong{Percentages}: pct_total, pct_pos, pct_neg, event_rate
  \item \strong{Cumulative Statistics}: cum_total, cum_pos, cum_neg, cum_event_rate
  \item \strong{Lift Metrics}: lift, cum_lift, capture_rate
  \item \strong{KS and Gini}: ks, gini
  \item \strong{Entropy and Information}: entropy, divergence, info_gain
  \item \strong{Risk Metrics}: odds, log_odds, relative_risk
  \item \strong{Performance Metrics}: precision, npv, f1_score, accuracy, balanced_acc, specificity
  \item \strong{Statistical Tests}: chi_square, z_score, p_value
  \item \strong{Stability and Concentration}: psi_component, concentration_ratio
  \item \strong{Additional Metrics}: miss_rate, fall_out, discovery_rate, mcc
}

The \code{summary_stats} includes:
\itemize{
  \item \code{base_rate}: Overall event rate
  \item \code{total_observations}: Total number of observations
  \item \code{max_ks}: Maximum KS statistic
  \item \code{auc}: Area Under ROC Curve
  \item \code{gini_coefficient}: Gini coefficient (2 * AUC - 1)
  \item \code{total_psi}: Total Population Stability Index
  \item \code{herfindahl_index}: Herfindahl-Hirschman Index
  \item \code{normalized_herfindahl}: Normalized HHI
  \item \code{total_iv}: Total Information Value
  \item \code{n_bins}: Number of bins
}
}
\description{
Function to compute comprehensive gains table metrics from WoE binning results. Calculates over 20 statistical
measures for evaluating binning quality, predictive power, and model performance.

The gains table provides detailed insights into how well each bin separates positive and negative cases,
enabling assessment of binning effectiveness and feature predictive power.
}
\details{
\strong{1) Core Metrics}

\emph{Basic Counts and Rates}:
\itemize{
  \item \code{total_count}, \code{pos_count}, \code{neg_count}: Raw counts per bin
  \item \code{event_rate}: Proportion of positive cases in each bin
  \item \code{pct_total}: Percentage of total population in each bin
}

\emph{Cumulative Statistics}:
\itemize{
  \item \code{cum_pos}: Cumulative percentage of positive cases (True Positive Rate/Sensitivity)
  \item \code{cum_neg}: Cumulative percentage of negative cases (False Positive Rate)
  \item \code{cum_event_rate}: Cumulative event rate
}

\strong{2) Performance Metrics}

\emph{Lift and Capture}:
\deqn{\text{Lift} = \frac{\text{Event Rate}}{\text{Base Rate}}}
\deqn{\text{Capture Rate} = \frac{\text{Cumulative Positives}}{\text{Total Positives}}}
where Base Rate is the overall proportion of positive cases.

\emph{KS Statistic}:
\deqn{\text{KS} = \max|\text{Cumulative Positives} - \text{Cumulative Negatives}|}
measuring the maximum separation between positive and negative distributions.

\emph{ROC Analysis}:
Area Under Curve (AUC) is calculated using the trapezoidal rule on the ROC curve:
\deqn{\text{AUC} = \sum_{i=1}^{n} \frac{\text{TPR}_i + \text{TPR}_{i-1}}{2} \times (\text{FPR}_{i-1} - \text{FPR}_i)}

\emph{Classification Metrics}:
\itemize{
  \item \code{precision} (Positive Predictive Value): \eqn{\frac{TP}{TP + FP}}
  \item \code{sensitivity} (True Positive Rate): \eqn{\frac{TP}{TP + FN}}
  \item \code{specificity} (True Negative Rate): \eqn{\frac{TN}{TN + FP}}
  \item \code{F1 Score}: \eqn{2 \times \frac{\text{precision} \times \text{sensitivity}}{\text{precision} + \text{sensitivity}}}
  \item \code{Matthews Correlation Coefficient}: \eqn{\frac{TP \times TN - FP \times FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}}
}

\strong{3) Information Theory Metrics}

\emph{Entropy}:
\deqn{H(p) = -p \log_2(p) - (1-p) \log_2(1-p)}
where \eqn{p} is the event rate in the bin.

\emph{Kullback-Leibler Divergence}:
\deqn{D_{KL}(p||q) = p \log\left(\frac{p}{q}\right) + (1-p) \log\left(\frac{1-p}{1-q}\right)}
measuring divergence from the base rate \eqn{q}.

\emph{Information Value Component}:
\deqn{\text{IV}_i = \left(\frac{\text{Count}_{1i}}{\text{Total}_1} - \frac{\text{Count}_{0i}}{\text{Total}_0}\right) \times \text{WoE}_i}

\strong{4) Statistical Tests}

\emph{Chi-Square Test} for each bin against the null hypothesis of independence.

\emph{Z-Score} for testing if bin event rate differs significantly from base rate:
\deqn{Z = \frac{p_1 - p_2}{\sqrt{p_{\text{pooled}}(1-p_{\text{pooled}})(\frac{1}{n_1} + \frac{1}{n_2})}}}
where \eqn{p_{\text{pooled}} = \frac{p_1 n_1 + p_2 n_2}{n_1 + n_2}}.
}
\section{Best practices for interpretation}{

\itemize{
  \item \strong{KS Statistic}: Values > 0.4 indicate good separation power
  \item \strong{AUC}: Values > 0.7 indicate acceptable discrimination
  \item \strong{Lift}: Values > 2 in top deciles indicate good targeting
  \item \strong{Capture Rate}: Should increase monotonically with cumulative percentage
  \item \strong{IV Components}: Large positive/negative values indicate strong predictive bins
}
}

\examples{
\dontrun{
# Assuming binning_result from chimerge_woe
gains_result <- woe_gains(binning_result, sort_by_woe = FALSE)

# View gains table for first feature
head(gains_result[[1]]$gains_table)

# View summary statistics
gains_result[[1]]$summary_stats

# Compare features using essential metrics only
simple_gains <- woe_gains(binning_result, include_all_metrics = FALSE)
}

}
\references{
\itemize{
  \item Siddiqi, N. (2006). Credit Risk Scorecards: Developing and Implementing Intelligent Credit Scoring. Wiley.
  \item Anderson, R. (2007). The Credit Scoring Toolkit: Theory and Practice for Retail Credit Risk Management and Decision Automation. Oxford University Press.
  \item Hand, D. J., & Henley, W. E. (1997). Statistical Classification Methods in Consumer Credit. Journal of the Royal Statistical Society, Series A, 160(3), 523-541.
  \item Kolmogorov, A. N. (1933). Sulla determinazione empirica di una legge di distribuzione. Giornale dell'Istituto Italiano degli Attuari, 4, 83-91.
  \item Smirnov, N. V. (1948). Table for Estimating the Goodness of Fit of Empirical Distributions. Annals of Mathematical Statistics, 19(2), 279-281.
}
}
\seealso{
\itemize{
  \item \code{chimerge_woe} for binning
  \item \code{woe_gains_compare} for feature comparison
}
}
\keyword{auc}
\keyword{gains-table}
\keyword{iv}
\keyword{ks-statistic}
\keyword{roc}
\keyword{woe}
